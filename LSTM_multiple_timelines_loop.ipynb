{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80874,"databundleVersionId":8794587,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ondrejmajor/rohlik-orders-prediction-lstm-w-result-plots?scriptVersionId=190007106\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Rohlík Data Preprocessing\nThis notebook contains a time series forecasting task on Rohlik dataset. EDA, data preprocessing and forecasting engine is LSTM model with Tensorflow 2 backend. \n\n<br><b>Approach:</b>\n<br>As Rohlík orders dataset contains data from multiple warehouses, thus it contains multiple timelines, the approach is to process and predict each warehouse as a separate timeline. The preprocessing, fitting and evaluation steps are the same for each warehouse. Very wide and shallow LSTM neural net (above 256 units) is used to process the feature rich dataset. Batch size is kept low enough (around 32) to keep the weekly spikes in target sharp.\n\n<br>This approach yields very good MAPE value, which is calculated as a mean of all warehouse timeline results.\n\n<b>This notebook is written with end-to-end mindset as if the models are to be deployed. Models, scalers and training configurations are saved. The test dataset is predicted on with inference style. The predictions can be done offline without the trainig notebook.","metadata":{}},{"cell_type":"code","source":"#! pip -q install pandas matplotlib numpy seaborn\n#! pip install -q scikit-learn\n#! pip install -q joblib\n#! pip install -q tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:47.964631Z","iopub.execute_input":"2024-07-27T14:12:47.965333Z","iopub.status.idle":"2024-07-27T14:12:47.970993Z","shell.execute_reply.started":"2024-07-27T14:12:47.965289Z","shell.execute_reply":"2024-07-27T14:12:47.96944Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Flatten, Reshape, LSTM, Dropout, Dense, Bidirectional, BatchNormalization, Input, LayerNormalization, Conv1D, Concatenate, MaxPooling1D, MultiHeadAttention, GlobalAveragePooling1D, Activation, SpatialDropout1D, Lambda\nfrom tensorflow.keras.losses import MeanSquaredError, Huber\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_percentage_error\nimport joblib\nimport os\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, RobustScaler\nfrom scipy import interpolate\nfrom sklearn.model_selection import KFold\n\nTIME_STEPS = 63\nEPOCHS = 25\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-3\n\n# NUM_FOLDS = 5 # Not implemented\n\nOFF_DAYS = False # Experimental. Fill missing days in timeseries as \"offday\" and fill features and target with 0s. \nLAG = True # add lag and rolling features\nFILL = True # fill nan with zeros before training\nSCALER = \"standard\" # standard best by far...\n\n#WAREHOUSE = [\"Prague_1\", \"Munich_1\", \"Budapest_1\"] # Train only particular warehouse timelines (For testing purposes)\nWAREHOUSE = [None]  # Train on all warehouses (whole dataset)\n\n\n# Temporal features\n#LAG_DAYS = [1, 7, 28, 56, 168, 364]  # more mainstream values\n#ROLLING_WINDOW = [7, 28, 168, 364]  # more mainstream values\nLAG_DAYS = [63, 119, 168, 364]  # this lag bridges the whole test dataset with past data\nROLLING_WINDOW = [63, 168, 364]  # this lag bridges the whole test dataset with past data\n\n\npd.set_option('display.max_columns', None)  # see all columns in pandas\n\ntrain_df_raw = pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/train.csv\")\ntrain_calendar_df_raw = pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/train_calendar.csv\")\ntest_df_raw = pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/test.csv\")\ntest_calendar_df_raw = pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/test_calendar.csv\")\n\ntrain_df_raw['date'] = pd.to_datetime(train_df_raw['date'])\ntrain_calendar_df_raw['date'] = pd.to_datetime(train_calendar_df_raw['date'])\ntest_df_raw['date'] = pd.to_datetime(test_df_raw['date'])\ntest_calendar_df_raw['date'] = pd.to_datetime(test_calendar_df_raw['date'])","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.007218Z","iopub.execute_input":"2024-07-27T14:12:48.008096Z","iopub.status.idle":"2024-07-27T14:12:48.087721Z","shell.execute_reply.started":"2024-07-27T14:12:48.008055Z","shell.execute_reply":"2024-07-27T14:12:48.086547Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## Optional - Dataset Validation\n\nEvaluate the correctness of the data from multiple sources. Check both .csvs if their values in the overlapping columns match and then merge them into one dataset.\n<br>After that we get train_df and test_df dataframes.","metadata":{}},{"cell_type":"code","source":"def merge_csv(train_df, train_calendar_df):\n    # Identify common columns\n    common_columns = set(train_df.columns).intersection(set(train_calendar_df.columns))\n    print(common_columns)\n\n    # Merg the two datasets on warehouse and date\n    merged_df_to_test = pd.merge(train_df, train_calendar_df, on=['date', 'warehouse'], suffixes=('_train', '_calendar'))\n    \n        # Compare values in common columns\n    differences = {}\n    for column in common_columns:\n        if column not in ['date', 'warehouse']:  # Exclude join keys from comparison\n            train_col = f\"{column}_train\"\n            calendar_col = f\"{column}_calendar\"\n            \n            # Check if there are any differences, excluding rows where both values are NaN\n            diff = merged_df_to_test[(merged_df_to_test[train_col] != merged_df_to_test[calendar_col]) & \n                            (~merged_df_to_test[train_col].isna() | ~merged_df_to_test[calendar_col].isna())]\n            if not diff.empty:\n                differences[column] = diff[['date', 'warehouse', train_col, calendar_col]]\n            else:\n                print(f\"No differences found in column: {column}\")\n\n    # Display only the rows where values were different\n    for col, diff in differences.items():\n        print(f\"\\nNot merged. Differences found in column: {col}\")\n        print(diff)\n        return\n\n    if not differences:\n        print(\"\\nAll values match across the datasets, datasets merged.\")\n        return pd.merge(train_df, train_calendar_df, on=list(common_columns))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.090191Z","iopub.execute_input":"2024-07-27T14:12:48.090639Z","iopub.status.idle":"2024-07-27T14:12:48.102313Z","shell.execute_reply.started":"2024-07-27T14:12:48.090599Z","shell.execute_reply":"2024-07-27T14:12:48.101135Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# Merg the two datasets on 'date' and 'warehouse' to facilitate comparison\ntrain_df_merged = merge_csv(train_df_raw, train_calendar_df_raw)\ntest_df_merged = merge_csv(test_df_raw, test_calendar_df_raw) ","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.103648Z","iopub.execute_input":"2024-07-27T14:12:48.104077Z","iopub.status.idle":"2024-07-27T14:12:48.182252Z","shell.execute_reply.started":"2024-07-27T14:12:48.104046Z","shell.execute_reply":"2024-07-27T14:12:48.181172Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"{'holiday', 'mov_change', 'mini_shutdown', 'precipitation', 'frankfurt_shutdown', 'warehouse', 'school_holidays', 'holiday_name', 'winter_school_holidays', 'blackout', 'shutdown', 'shops_closed', 'date', 'snow'}\nNo differences found in column: holiday\nNo differences found in column: mov_change\nNo differences found in column: mini_shutdown\nNo differences found in column: precipitation\nNo differences found in column: frankfurt_shutdown\nNo differences found in column: school_holidays\nNo differences found in column: holiday_name\nNo differences found in column: winter_school_holidays\nNo differences found in column: blackout\nNo differences found in column: shutdown\nNo differences found in column: shops_closed\nNo differences found in column: snow\n\nAll values match across the datasets, datasets merged.\n{'holiday', 'warehouse', 'holiday_name', 'winter_school_holidays', 'shops_closed', 'date', 'school_holidays'}\nNo differences found in column: holiday\nNo differences found in column: holiday_name\nNo differences found in column: winter_school_holidays\nNo differences found in column: shops_closed\nNo differences found in column: school_holidays\n\nAll values match across the datasets, datasets merged.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Sort the datasets by 'date' and 'warehouse' ascendingly\n\ntrain_df = train_df_merged.sort_values(by=['date', 'warehouse'])\ntest_df = test_df_merged.sort_values(by=['date', 'warehouse'])","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.18492Z","iopub.execute_input":"2024-07-27T14:12:48.185274Z","iopub.status.idle":"2024-07-27T14:12:48.197658Z","shell.execute_reply.started":"2024-07-27T14:12:48.185243Z","shell.execute_reply":"2024-07-27T14:12:48.196454Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## Drop unnecesary data\nThere are some features in the training set that are not availiable in the testing set, so we do not use them.\n<br>The \"orders\" column we keep as it is our target.","metadata":{}},{"cell_type":"code","source":"# get features that are not available in the test dataset\nunavailable_features = list(set(train_df.columns).difference(set(test_df.columns)))    \nunavailable_features.remove('orders')\n\nprint(f\"Common features: {unavailable_features}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.199236Z","iopub.execute_input":"2024-07-27T14:12:48.199671Z","iopub.status.idle":"2024-07-27T14:12:48.207535Z","shell.execute_reply.started":"2024-07-27T14:12:48.199631Z","shell.execute_reply":"2024-07-27T14:12:48.206317Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Common features: ['mov_change', 'precipitation', 'mini_shutdown', 'frankfurt_shutdown', 'user_activity_1', 'warehouse_limited', 'user_activity_2', 'blackout', 'shutdown', 'snow']\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = train_df.drop(columns=unavailable_features)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.2091Z","iopub.execute_input":"2024-07-27T14:12:48.209494Z","iopub.status.idle":"2024-07-27T14:12:48.225254Z","shell.execute_reply.started":"2024-07-27T14:12:48.209456Z","shell.execute_reply":"2024-07-27T14:12:48.223821Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"Columns that have unchanging values or very little movement, sometimes redundant features.\n<br> We look as binary features that might be alway 0 or 1.\n<br> \"school_holidays\" and \"shops_closed\" are redundant in some warehouses\n<br> We can drop these columns as they are redundant but in this run we leave it.","metadata":{}},{"cell_type":"code","source":"# Run the code to identify and drop unchanging columns\n\nfor warehouse in train_df['warehouse'].unique():\n    unchanging_columns = []\n    print(f\"\\nWarehouse: {warehouse}\")\n    for feature in train_df.columns:\n        if feature in ['warehouse', 'date']:\n            continue\n\n        values = train_df[train_df['warehouse'] == warehouse][feature].nunique()\n        if values == 1:\n            print(f\"Feature {feature} has {values} unique values\")\n            print(f\"Value: {train_df[train_df['warehouse'] == warehouse][feature].unique()}\")\n            if feature not in unchanging_columns:\n                unchanging_columns.append(feature)\n        if values == 2:\n            print(f\"Feature {feature} has {values} unique values\")\n            true_count = sum(train_df[train_df['warehouse'] == warehouse][feature] == 1)\n            total_count = len(train_df[train_df['warehouse'] == warehouse])\n            print(f\"{true_count} items True of {total_count}\")\n\n    print(f\"    Unchanging columns in {warehouse}: {unchanging_columns}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.227358Z","iopub.execute_input":"2024-07-27T14:12:48.227757Z","iopub.status.idle":"2024-07-27T14:12:48.465894Z","shell.execute_reply.started":"2024-07-27T14:12:48.22771Z","shell.execute_reply":"2024-07-27T14:12:48.464763Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"\nWarehouse: Brno_1\nFeature holiday has 2 unique values\n45 items True of 1193\nFeature shops_closed has 2 unique values\n20 items True of 1193\nFeature winter_school_holidays has 2 unique values\n28 items True of 1193\nFeature school_holidays has 1 unique values\nValue: [0]\n    Unchanging columns in Brno_1: ['school_holidays']\n\nWarehouse: Budapest_1\nFeature holiday has 2 unique values\n9 items True of 1154\nFeature shops_closed has 1 unique values\nValue: [0]\nFeature winter_school_holidays has 2 unique values\n6 items True of 1154\nFeature school_holidays has 1 unique values\nValue: [0]\n    Unchanging columns in Budapest_1: ['shops_closed', 'school_holidays']\n\nWarehouse: Prague_1\nFeature holiday has 2 unique values\n45 items True of 1193\nFeature shops_closed has 2 unique values\n20 items True of 1193\nFeature winter_school_holidays has 2 unique values\n84 items True of 1193\nFeature school_holidays has 1 unique values\nValue: [0]\n    Unchanging columns in Prague_1: ['school_holidays']\n\nWarehouse: Prague_2\nFeature holiday has 2 unique values\n45 items True of 1193\nFeature shops_closed has 2 unique values\n20 items True of 1193\nFeature winter_school_holidays has 2 unique values\n28 items True of 1193\nFeature school_holidays has 1 unique values\nValue: [0]\n    Unchanging columns in Prague_2: ['school_holidays']\n\nWarehouse: Prague_3\nFeature holiday has 2 unique values\n45 items True of 1193\nFeature shops_closed has 2 unique values\n20 items True of 1193\nFeature winter_school_holidays has 2 unique values\n28 items True of 1193\nFeature school_holidays has 1 unique values\nValue: [0]\n    Unchanging columns in Prague_3: ['school_holidays']\n\nWarehouse: Munich_1\nFeature holiday has 2 unique values\n6 items True of 785\nFeature shops_closed has 1 unique values\nValue: [0]\nFeature winter_school_holidays has 2 unique values\n29 items True of 785\nFeature school_holidays has 2 unique values\n28 items True of 785\n    Unchanging columns in Munich_1: ['shops_closed']\n\nWarehouse: Frankfurt_1\nFeature holiday has 2 unique values\n5 items True of 629\nFeature shops_closed has 1 unique values\nValue: [0]\nFeature winter_school_holidays has 2 unique values\n17 items True of 629\nFeature school_holidays has 2 unique values\n24 items True of 629\n    Unchanging columns in Frankfurt_1: ['shops_closed']\n","output_type":"stream"}]},{"cell_type":"code","source":"# What is the gap between the date of the last training data and the first test data?\ntrain_max_date = train_df['date'].max()\ntest_min_date = test_df['date'].min()\nprint(f\"Train max date: {train_max_date}\")\nprint(f\"Test min date: {test_min_date}\")\nprint(f\"Gap: {test_min_date - train_max_date}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.469677Z","iopub.execute_input":"2024-07-27T14:12:48.470066Z","iopub.status.idle":"2024-07-27T14:12:48.478061Z","shell.execute_reply.started":"2024-07-27T14:12:48.470035Z","shell.execute_reply":"2024-07-27T14:12:48.476692Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Train max date: 2024-03-15 00:00:00\nTest min date: 2024-03-16 00:00:00\nGap: 1 days 00:00:00\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Experimental - Line-up all warehouse timelines in the same time format.\nThis is experimental function with a purpose:\n\n-   When we examine the dataset, we can see that some warehouses do not operate at sundays. \n-   Some warehouses are missing a lot of days rom first months as they were just setting up oin new markets.\n-   There are missing days on other warehouses sometimes.\n-   <b>This function introduces</b> a new feature <b>\"off_day\"</b>, which is 1 whenever we have missing day in the dataset.\n- Currently diabled, uncomment last line bellow to experiment.","metadata":{}},{"cell_type":"code","source":"def process_warehouses(train_df, handle_off_days='interpolate'):\n    \"\"\"\n    Process each warehouse and handle off days based on the specified method.\n    \n    Parameters:\n    train_df (DataFrame): The input DataFrame containing warehouse data.\n    handle_off_days (str): The method to handle off days, either 'interpolate' or 'zeros'.\n    \n    Returns:\n    DataFrame: The processed DataFrame with all warehouses combined.\n    \"\"\"\n    combined_df_list = []\n    start_dates_info = []\n\n    for warehouse in train_df['warehouse'].unique():\n        wh = train_df[train_df['warehouse'] == warehouse]\n        \n        # Fix specific warehouses with unconisitent data at the start\n        if warehouse == 'Frankfurt_1':\n            first_month_end = wh['date'].min() + pd.DateOffset(days=4)\n            wh = wh[wh['date'] > first_month_end]\n        if warehouse == 'Munich_1':\n            first_month_end = wh['date'].min() + pd.DateOffset(weeks=5)\n            wh = wh[wh['date'] > first_month_end]\n            \n        wh.set_index('date', inplace=True)\n        date_range = pd.date_range(start=wh.index.min(), end=wh.index.max(), freq='D')\n        wh_reindexed = wh.reindex(date_range).reset_index()\n        wh_reindexed.rename(columns={'index': 'date'}, inplace=True)\n        \n        # Add off_day column\n        wh_reindexed['off_day'] = wh_reindexed['orders'].isna().astype(int)\n        \n        # Here we have to fill in the missing features for the off days, mostly 0s here, we do not count holidays, etc. for missing days for now.\n        wh_reindexed['warehouse'] = warehouse\n        wh_reindexed['holiday_name'] = wh_reindexed['holiday_name'].fillna('')\n        wh_reindexed['holiday'] = wh_reindexed['holiday'].fillna(0)\n        wh_reindexed['shops_closed'] = wh_reindexed['shops_closed'].fillna(0)\n        wh_reindexed['winter_school_holidays'] = wh_reindexed['winter_school_holidays'].fillna(0)\n        wh_reindexed['school_holidays'] = wh_reindexed['school_holidays'].fillna(0)\n        \n        if handle_off_days == 'interpolate':\n            wh_reindexed['orders'] = wh_reindexed['orders'].interpolate(method='linear')\n        elif handle_off_days == 'zeros':\n            wh_reindexed['orders'] = wh_reindexed['orders'].fillna(0.0)\n        \n        # the 'id' column is for the test dataset mostly\n        wh_reindexed['id'] = wh_reindexed.apply(lambda row: f\"{row['warehouse']}_{row['date'].strftime('%Y-%m-%d')}\", axis=1)\n        wh_reindexed['day_of_week'] = wh_reindexed['date'].dt.dayofweek + 1  # Monday=1, Sunday=7\n        \n        # Cut off data to start on the earliest Monday - all warehouses start on timeline on Monday, so they hawe weekly overlap.\n        start_date = wh_reindexed['date'].min()\n        end_date = wh_reindexed['date'].max()\n        start_monday = start_date - pd.Timedelta(days=start_date.weekday())\n        end_sunday = end_date + pd.Timedelta(days=(6 - end_date.weekday()))\n        wh_reindexed = wh_reindexed[(wh_reindexed['date'] >= start_monday) & (wh_reindexed['date'] <= end_sunday)]\n        \n        # get info about the start date \n        start_dates_info.append(f\"{warehouse}: Start Date: {start_monday.strftime('%Y-%m-%d')} (Day {start_monday.weekday() + 1})\")\n\n        # get all new dataframes into a list\n        combined_df_list.append(wh_reindexed)\n        \n        # Plot\n        plt.figure(figsize=(20, 10))\n        plt.plot(wh_reindexed['date'], wh_reindexed['orders'], marker='x', linestyle='-', markersize=3, linewidth=0.5, label='Orders')\n\n        # start of the first week and end of the last week\n        plt.axvline(x=start_monday, color='r', linestyle='--', linewidth=0.5, label='Start of first week')\n        plt.axvline(x=end_sunday, color='g', linestyle='--', linewidth=0.5, label='End of last week')\n        \n        # Highlight the off days\n        off_days = wh_reindexed[wh_reindexed['off_day'] == 1]\n        plt.scatter(off_days['date'], off_days['orders'], color='red', s=15, label='Off days', marker='o')\n        \n        # Mark the weekdays on off days\n        for idx, row in wh_reindexed.iterrows():\n            if row['off_day'] == 1:\n                plt.text(row['date'], row['orders'], str(row['day_of_week']), color='black', ha='center', va='bottom', fontsize=10)\n\n        plt.title(f\"Volume for warehouse {warehouse}\")\n        plt.xlabel('Date')\n        plt.ylabel('Orders')\n        plt.legend()\n        plt.xticks(rotation=45)\n        plt.show()\n\n        # Drop day_of_week column , we will be adding it later as a feature\n        wh_reindexed.drop(columns=['day_of_week'], inplace=True)\n\n    # Print start dates for each warehouse\n    print(\"Start Dates for Each Warehouse:\")\n    for info in start_dates_info:\n        print(info)\n\n    # Combine all warehouses into one DataFrame\n    train_df_reindexed = pd.concat(combined_df_list, ignore_index=True)\n    \n    return train_df_reindexed\n\n# Uncomment to use this function\nif OFF_DAYS:\n    train_df = process_warehouses(train_df, handle_off_days='zeros') # zero or interpolate - zero makes more sense but still confuses the model durin training. Interpolate is purely experimental.","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:12:48.480181Z","iopub.execute_input":"2024-07-27T14:12:48.480625Z","iopub.status.idle":"2024-07-27T14:12:48.508861Z","shell.execute_reply.started":"2024-07-27T14:12:48.480582Z","shell.execute_reply":"2024-07-27T14:12:48.507603Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"We are merging train and test datasets and process it as one dataset, so we can apply temporal features on both datasets. We will get lag days on the test dataset. Later we split dataset back to train and test for training and prediction.","metadata":{}},{"cell_type":"code","source":"# merge the two datasets\ntrain_df = pd.concat([train_df, test_df], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In our test dataset is not a lot of holidays that had inpact on \"orders\" in previous years so we are not going to use it. \n<br>It could be used with one-hot encoding and a bit experimentuing.","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop(columns=['holiday_name'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.sort_values(by=['date', 'warehouse'], ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# only get data of one warehouse for the dataset - for testing purposes\nif WAREHOUSE != [None]:\n    train_df = train_df[train_df['warehouse'].isin(WAREHOUSE)]\n    print(\"ran\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Produce date features\nThis function processes the date column and produces multiple time features from it.","metadata":{}},{"cell_type":"code","source":"from math import pi\ndef process_date(df):\n    \n    df['date'] = pd.to_datetime(df['date'])\n    \n    # Extract date-related features\n    df['quarter'] = df['date'].dt.quarter\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df['day_of_week'] = df['date'].dt.dayofweek\n    df['day_of_year'] = df['date'].dt.dayofyear\n    \n    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n\n    \n    # Calculate days since the start date\n    df['days_since_start'] = (df['date'] - df['date'].min()).dt.days\n    \n    \n    # Create cyclic features\n    def cyclical_encode(df, col, max_val):\n        df[f'{col}_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n        df[f'{col}_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n    \n    cyclical_encode(df, 'month', 12)\n    cyclical_encode(df, 'day_of_week', 7)\n    #cyclical_encode(df, 'day_of_year', 365)\n    #cyclical_encode(df, 'day', 30)\n\n    cat_features = [\"day_of_week\", 'quarter', 'month']\n    bin_features = ['is_weekend']\n    return df, cat_features, bin_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply process_date function and save the categorical and binary features for later use.\n\ntrain_df, categorical_features, binary_features=process_date(train_df)\n\nif OFF_DAYS:\n    binary_features = binary_features + ['holiday', 'shops_closed', 'winter_school_holidays', 'school_holidays', 'off_day']\nelse:\n    binary_features = binary_features + ['holiday', 'shops_closed', 'winter_school_holidays', 'school_holidays']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We keep track of important parameters and settings during the training phase, as it is good habbit when later deploying machine learning models for inference.\n<br>Here we are tracking features that will be passed through the scalers.","metadata":{}},{"cell_type":"code","source":"x_scaler_features = list(set(train_df.columns) - set(categorical_features) - set(binary_features) - {'warehouse', 'orders', 'id', 'date'})\nprint(x_scaler_features)\nprint(categorical_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if \"off_day\" in binary_features:\n    train_df['off_day'] = train_df['off_day'].fillna(0)\n\n    orders = train_df[\"orders\"]\n    train_df = train_df.fillna(0)\n    train_df[\"orders\"] = orders","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review dataset before proecssing\ntrain_df.head(7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation Matrix","metadata":{}},{"cell_type":"code","source":"train_df_corr = train_df.drop(columns=['warehouse', \"id\"]).corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.heatmap(train_df_corr, annot=True, cmap='coolwarm', fmt='.2f')\nplt.title('Correlation Matrix')\nplt.show()\n\n# Print the correlation with 'orders'\nprint(train_df_corr['orders'].sort_values(ascending=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Produce temporal features\nCreate lag and rolling window features.","metadata":{}},{"cell_type":"code","source":"def create_lag_features(df, col, lag_days):\n    df = df.copy()\n    lag_features = []\n    for lag in lag_days:\n        feature_name = f'{col}_lag_{lag}'\n        df[feature_name] = df[col].shift(lag)\n        lag_features.append(feature_name)\n    return df, lag_features\n\ndef create_rolling_features(df, col, windows):\n    df = df.copy()\n    window_features = []\n    for window in windows:\n        mean_feature = f'{col}_rolling_mean_{window}'\n        std_feature = f'{col}_rolling_std_{window}'\n        \n        df[mean_feature] = df[col].rolling(window, min_periods=1).mean()\n        df[std_feature] = df[col].rolling(window, min_periods=1).std()\n        \n        window_features.extend([mean_feature, std_feature])\n    return df, window_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(df, cat_features, x_scaler_features, binary_features, redundant_features=[], inference=False, fill_method='ffill', lag = True):\n    warehouse = df['warehouse'].iloc[0]\n    redundant_df = df[redundant_features]\n    df = df.drop(columns=redundant_features)\n    \n    if inference is False and lag is True:\n        # Create lag and rolling features\n        df, lag_features = create_lag_features(df, 'orders', LAG_DAYS)\n        df, window_features = create_rolling_features(df, 'orders', ROLLING_WINDOW)\n        \n        x_scaler_features = x_scaler_features + lag_features + window_features\n        \n        # Handle NaN values in lag and rolling features\n        if fill_method == 'ffill':\n            df[lag_features + window_features] = df[lag_features + window_features].ffill().bfill()\n            orders = df[\"orders\"]\n            df = df.ffill().bfill()\n            df[\"orders\"] = orders\n            \n        elif fill_method == 'zero':\n            df[lag_features + window_features] = df[lag_features + window_features].fillna(0)\n            orders = df[\"orders\"]\n            df = df.fillna(0)\n            df[\"orders\"] = orders\n    \n    # One-hot encoding for categorical features\n    if not inference:\n        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n        encoded_features = encoder.fit_transform(df[cat_features])\n        joblib.dump(encoder, f'onehot_scaler_{warehouse}.joblib')\n    else:\n        encoder = joblib.load(f'onehot_scaler_{warehouse}.joblib')\n        encoded_features = encoder.transform(df[cat_features])\n\n    encoded_feature_names = encoder.get_feature_names_out(cat_features)\n    encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names, index=df.index)\n\n    # Prepare features for scaling\n    if inference is False:\n        X = df.drop(columns=['orders'])\n        y = df['orders']\n    else:\n        X = df\n\n    # Initialize and fit/transform scalers\n    if not inference:\n        if SCALER == \"minmax\":\n            x_scaler = MinMaxScaler(feature_range=(0, 1))\n            y_scaler = MinMaxScaler(feature_range=(0, 1))\n        elif SCALER == \"robust\":\n            x_scaler = RobustScaler()\n            y_scaler = RobustScaler()\n        else:\n            x_scaler = StandardScaler()\n            y_scaler = StandardScaler()\n        X_scaled = x_scaler.fit_transform(X[x_scaler_features])\n        y_scaled = y_scaler.fit_transform(y.values.reshape(-1, 1))\n        joblib.dump(x_scaler, f'x_scaler_{warehouse}.joblib')\n        joblib.dump(y_scaler, f'y_scaler_{warehouse}.joblib')\n    else:\n        x_scaler = joblib.load(f'x_scaler_{warehouse}.joblib')\n        X_scaled = x_scaler.transform(X[x_scaler_features])\n        #y_scaler = joblib.load(f'y_scaler_{warehouse}.joblib')\n        #y_scaled = y_scaler.transform(y.values.reshape(-1, 1))\n\n    # Create DataFrame with scaled features\n    X_scaled_df = pd.DataFrame(X_scaled, columns=x_scaler_features, index=df.index)\n\n    # Combine all features\n    final_df = pd.concat([\n        X_scaled_df,  # Scaled numerical features\n        encoded_df,   # One-hot encoded categorical features\n        df[binary_features],  # Binary features (unchanged)\n        redundant_df  # Add redundant features back for the test data export\n    ], axis=1)\n    \n    if inference:\n        print(final_df.shape)\n        return final_df\n    else:\n        print(final_df.shape, y_scaled.shape)\n        return final_df, y_scaled","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing Function\nThis is preprocessing function that applies:\n<br>lag features\n<br>one-hot encoding of categorical features\n<br>feature-target split\n<br>feature, target scaling\n<br>return the final dataframe","metadata":{}},{"cell_type":"markdown","source":"## Outliers Reduction Function\nFunction to fix outliers - orders that are very high or very low. \n<br>Plot the outliers.\n<br>Settings of the z-score and window that is outliers calculated with.","metadata":{}},{"cell_type":"code","source":"if not OFF_DAYS:\n    def z_score_outlier_detection(data, window=14, threshold=3):\n        data = data.sort_index()\n        rolling_mean = data.rolling(window=window, center=True, min_periods=1).mean()\n        rolling_std = data.rolling(window=window, center=True, min_periods=1).std()\n        z_scores = (data - rolling_mean) / rolling_std\n        outliers = (np.abs(z_scores) > threshold) & (data != 0)\n        lower_bound = rolling_mean - (threshold * rolling_std)\n        upper_bound = rolling_mean + (threshold * rolling_std)\n        return outliers, lower_bound, upper_bound\n\n\n    def weighted_trend_interpolation(data, outliers, window_size=10, weight=0.5):\n        fixed_data = data.copy()\n        for idx in np.where(outliers)[0]:\n            start_idx = max(0, idx - window_size)\n            end_idx = min(len(data), idx + window_size + 1)\n\n            prev_values = data.iloc[start_idx:idx].dropna()\n            next_values = data.iloc[idx + 1:end_idx].dropna()\n\n            #print(f\"Previous values: {prev_values}\\n\")\n            #print(f\"Next values: {next_values}\\n\")\n\n            if len(prev_values) == 0:\n                correction = next_values.mean()\n            elif len(next_values) == 0:\n                correction = prev_values.mean()\n            else:\n                mean_prev = prev_values.mean()\n                mean_next = next_values.mean()\n\n                if mean_next > mean_prev:\n                    trend = 'up'\n                else:\n                    trend = 'down'\n\n                # Calculate new value based on trend and retain some of the original intensity\n                if trend == 'up':\n                    correction = mean_prev + (next_values.mean() - mean_prev) / 2\n                else:\n                    correction = mean_prev - (mean_prev - next_values.mean()) / 2\n\n            if np.isnan(correction):  # Handle cases where both prev_values and next_values are NaN\n                correction = data.iloc[idx]\n\n            fixed_data.iloc[idx] = weight * data.iloc[idx] + (1 - weight) * correction\n\n            #print(f\"Outlier at index {idx}: {data.iloc[idx]} -> {fixed_data.iloc[idx]}\")\n        return fixed_data\n\n\n    def plot_outlier_comparison(df, window=28, z_threshold=3, window_size=10, weight=0.5):\n        warehouse_data = df['orders']\n\n        z_outliers, z_lower, z_upper = z_score_outlier_detection(warehouse_data, window, z_threshold)\n        fixed_warehouse_data = weighted_trend_interpolation(warehouse_data, z_outliers, window_size, weight)\n\n        # Plot the original data and outliers\n        plt.figure(figsize=(20, 10))\n        plt.plot(warehouse_data.index, warehouse_data, label='Orders', alpha=0.7)\n        plt.fill_between(warehouse_data.index, z_lower, z_upper, color='green', alpha=0.1, label='Z-Score Bounds')\n        plt.scatter(warehouse_data.index[z_outliers], warehouse_data[z_outliers], color='blue', label='Z-Score Outliers', marker='s')\n\n        # Plot fixed outliers\n        plt.scatter(warehouse_data.index[z_outliers], fixed_warehouse_data[z_outliers], color='green', label='Fixed Outliers', marker='x')\n        plt.title(f'{df[\"warehouse\"].iloc[0]} - Outlier Comparison')\n        plt.xlabel('Date')\n        plt.ylabel('Orders')\n        plt.legend()\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n\n        print(f\"\\n{df['warehouse'].iloc[0]}:\")\n        print(f\"Z-Score Outliers: {sum(z_outliers)}\")\n\n        # Update the DataFrame with fixed values\n        df.loc[:, 'orders'] = fixed_warehouse_data\n\n        return df\n\n\n\nelse:\n    def z_score_outlier_detection(data, window=14, threshold=3):\n        # Exclude rows where 'off_day' == 1\n        mask = data['off_day'] != 1\n        data_filtered = data[mask].copy()\n        data_filtered['orders'] = data_filtered['orders'].sort_index()\n\n        rolling_mean = data_filtered['orders'].rolling(window=window, center=True, min_periods=1).mean()\n        rolling_std = data_filtered['orders'].rolling(window=window, center=True, min_periods=1).std()\n        z_scores = (data_filtered['orders'] - rolling_mean) / rolling_std\n        outliers_filtered = (np.abs(z_scores) > threshold) & (data_filtered['orders'] != 0)\n        lower_bound_filtered = rolling_mean - (threshold * rolling_std)\n        upper_bound_filtered = rolling_mean + (threshold * rolling_std)\n\n        # Create full-length arrays with NaN for excluded indices\n        outliers = pd.Series(np.nan, index=data.index)\n        lower_bound = pd.Series(np.nan, index=data.index)\n        upper_bound = pd.Series(np.nan, index=data.index)\n\n        outliers[mask] = outliers_filtered\n        lower_bound[mask] = lower_bound_filtered\n        upper_bound[mask] = upper_bound_filtered\n\n        return outliers, lower_bound, upper_bound\n\n    def weighted_trend_interpolation(data, outliers, window_size=10, weight=0.5):\n        fixed_data = data['orders'].copy()\n        for idx in np.where(outliers)[0]:\n            start_idx = max(0, idx - window_size)\n            end_idx = min(len(data), idx + window_size + 1)\n\n            prev_values = data['orders'].iloc[start_idx:idx].dropna()\n            next_values = data['orders'].iloc[idx + 1:end_idx].dropna()\n\n            if len(prev_values) == 0:\n                correction = next_values.mean()\n            elif len(next_values) == 0:\n                correction = prev_values.mean()\n            else:\n                mean_prev = prev_values.mean()\n                mean_next = next_values.mean()\n\n                if mean_next > mean_prev:\n                    trend = 'up'\n                else:\n                    trend = 'down'\n\n                # Calculate new value based on trend and retain some of the original intensity\n                if trend == 'up':\n                    correction = mean_prev + (next_values.mean() - mean_prev) / 2\n                else:\n                    correction = mean_prev - (mean_prev - next_values.mean()) / 2\n\n            if np.isnan(correction):  # Handle cases where both prev_values and next_values are NaN\n                correction = data['orders'].iloc[idx]\n\n            fixed_data.iloc[idx] = weight * data['orders'].iloc[idx] + (1 - weight) * correction\n\n        return fixed_data\n\n    def plot_outlier_comparison(df, window=28, z_threshold=3, window_size=10, weight=0.5):\n        warehouse_data = df[['orders', 'off_day']]\n        non_off_day_data = warehouse_data[warehouse_data['off_day'] != 1]\n\n        z_outliers, z_lower, z_upper = z_score_outlier_detection(warehouse_data, window, z_threshold)\n        fixed_warehouse_data = weighted_trend_interpolation(warehouse_data, z_outliers, window_size, weight)\n\n        # Plot the original data and outliers\n        plt.figure(figsize=(20, 10))\n        plt.plot(non_off_day_data.index, non_off_day_data['orders'], label='Orders', alpha=0.7)\n        plt.fill_between(warehouse_data.index, z_lower, z_upper, color='green', alpha=0.1, label='Z-Score Bounds')\n        plt.scatter(warehouse_data.index[z_outliers.dropna().index], warehouse_data['orders'][z_outliers.dropna().index], color='blue', label='Z-Score Outliers', marker='s')\n\n        # Plot fixed outliers\n        plt.scatter(warehouse_data.index[z_outliers.dropna().index], fixed_warehouse_data[z_outliers.dropna().index], color='green', label='Fixed Outliers', marker='x')\n        plt.title(f'{df[\"warehouse\"].iloc[0]} - Outlier Comparison')\n        plt.xlabel('Date')\n        plt.ylabel('Orders')\n        plt.legend()\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n\n        print(f\"\\n{df['warehouse'].iloc[0]}:\")\n        print(f\"Z-Score Outliers: {sum(z_outliers.dropna())}\")\n\n        # Update the DataFrame with fixed values\n        df.loc[:, 'orders'] = fixed_warehouse_data\n\n        return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_df['date'].min())\nprint(test_df['date'].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Data for Each Warehouse, Data Visualisations\nPut all above together in a loop that produces:\n\n- Reduces outliers\n- Train dataframe dictionary for every warehouse a dataframe\n- Test dataframe with lag features and scaled \n- Extra dates from train data added to the test dataset to create LSTM sequences from later.\n","metadata":{}},{"cell_type":"code","source":"from datetime import timedelta\n\n\nfeatures = [f'orders_lag_{lag}' for lag in LAG_DAYS]\nfeatures2 = [f'orders_rolling_mean_{window}' for window in ROLLING_WINDOW]\n\nwarehouses = train_df['warehouse'].unique()\n\n# Create dataframes for each warehouse\nwarehouse_dfs = {wh: train_df[train_df['warehouse'] == wh].copy() for wh in warehouses}\n\n\nprocessed_train_data_dict = {}\nprocessed_test_data = []\n\nfor warehouse, df in warehouse_dfs.items():\n    print(f\"Processing warehouse: {warehouse}\")\n    \n    \n    \n    df = df.sort_values(by=['date'])\n    \n    # Get the date range for test dataset.\n    test_min_date = test_df['date'].min()\n    test_max_date = test_df['date'].max()\n    \n    # Get the first date of the test data adding extra dates to it for the sequences for LSTM.\n    start_date = test_min_date - (2*timedelta(days=TIME_STEPS))\n    \n    # Get indices for the specified date range for the test dataset.\n    selected_indices = df[(df['date'] >= start_date) & (df['date'] <= test_max_date)].index\n    # Indicies to drop from train data, tat only include the real test data from the real test dataset.\n    test_indices = df[(df['date'] >= test_min_date) & (df['date'] <= test_max_date)].index\n    \n    # Plot outlier setup\n    df = plot_outlier_comparison(df, window=70, z_threshold=2.8, weight=0.5)\n\n    # Preprocess data\n    X_processed, y_processed = preprocess_data(df, \n                                               categorical_features, \n                                               x_scaler_features, \n                                               binary_features, \n                                               redundant_features=['warehouse', 'id', 'date'], \n                                               inference=False, \n                                               fill_method='ffill',\n                                               lag=LAG)\n    \n    \n    \n    \n    test_data = X_processed.loc[selected_indices]\n    \n    selected_positions = X_processed.index.get_indexer(selected_indices)\n    test_positions = X_processed.index.get_indexer(test_indices)\n    \n    X_processed = X_processed.drop(test_indices)\n    y_processed = np.delete(y_processed, test_positions)\n    \n    processed_test_data.append(test_data)\n    processed_train_data_dict[warehouse] = (X_processed, y_processed)\n    \n    print(f\"Processed:\\ntrain data shape: {X_processed.shape}, {y_processed.shape}\")\n    print(\"test data shape:\", test_data.shape)\n    print(f\"y nans: {sum(np.isnan(y_processed))}\")\n    print(\"\\n\")\n\n# create test dataframe for the test data for each warehouse\nprocessed_test_df = pd.concat(processed_test_data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Export Processed Test Data","metadata":{}},{"cell_type":"code","source":"if FILL:\n    processed_test_df = processed_test_df.fillna(0)\n    processed_test_df.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(processed_test_df.isna().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Processed test dataset length: {len(processed_test_df)}\")\nprint(f\"Raw test dataset length: {len(test_df_raw)}\")\n# Save the test dataset for future use\nprocessed_test_df.to_csv('/kaggle/working/test_proc_mt.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot the test data\nVisualise the training dataset with new features for every warehouse timeline","metadata":{}},{"cell_type":"code","source":"if LAG:\n    features = [f'orders_lag_{lag}' for lag in LAG_DAYS]\n    features2 = [f'orders_rolling_mean_{window}' for window in ROLLING_WINDOW]\n\n    def is_weekend(date):\n        return date.weekday() >= 5\n\n    # Plot the processed test data:\n\n    for wh in processed_test_df['warehouse'].unique():\n        wh_df = processed_test_df[processed_test_df['warehouse'] == wh]\n        plt.figure(figsize=(20, 10))\n\n        plt.plot(wh_df[\"date\"], wh_df[features[0]], label=features[0])\n        plt.plot(wh_df[\"date\"], wh_df[features[1]], label=features[1])\n        plt.plot(wh_df[\"date\"], wh_df[features[2]], label=features[2])\n        plt.plot(wh_df[\"date\"], wh_df[features[3]], label=features[3])\n        plt.plot(wh_df[\"date\"], wh_df[features2[0]], label=features2[0])\n        plt.plot(wh_df[\"date\"], wh_df[features2[1]], label=features2[1])\n        plt.plot(wh_df[\"date\"], wh_df[features2[2]], label=features2[2])\n\n        # Shade weekends\n        wh_df['is_weekend'] = wh_df['date'].apply(is_weekend)\n        weekends = wh_df[wh_df['is_weekend']]\n        for i, row in weekends.iterrows():\n            plt.axvspan(row['date'], row['date'] + pd.Timedelta(days=1), color='gray', alpha=0.3)\n\n        plt.title(f'{wh} - Processed Test Data')\n        plt.xlabel('Date')\n        plt.ylabel('Orders')\n        plt.legend()\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot LAG features\nVisualise LAG features of train and test back to back with the real orders","metadata":{}},{"cell_type":"code","source":"if LAG:\n    feature = f'orders_lag_{LAG_DAYS[2]}'  # third lag feature for test data\n\n    # Loop through the warehouse dataframes in the dictionary\n    for warehouse in processed_train_data_dict.keys():\n        plt.figure(figsize=(15, 5))\n\n        # Get train data for the warehouse\n        train_orders = processed_train_data_dict[warehouse][1]  # X_processed\n        train_data = processed_train_data_dict[warehouse][0]  # X_processed\n\n        # Get test data for the warehouse\n        test_data = processed_test_df[processed_test_df['warehouse'] == warehouse]\n\n        # Plot the orders and the feature\n        plt.plot(train_data.index, train_orders, label='Train Orders', color='green')\n        plt.plot(train_data.index, train_data[feature], label=f'Train {feature}', color='blue')\n        plt.plot(test_data.index, test_data[feature], label=f'Test {feature}', color='red')\n        \n        plt.title(f'Train and Test for {warehouse} Warehouse - {feature}')\n        plt.xlabel('Date')\n        plt.ylabel('Orders')\n        plt.legend()\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for warehouse, (X_processed, y_processed) in processed_train_data_dict.items():\n    print(f\"Warehouse: {warehouse}\")\n    print(\"Start Date:\", X_processed[\"date\"].min())\n    print(\"End Date:\", X_processed[\"date\"].max())\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review dataset before training\nprint(len(processed_train_data_dict[warehouse][0]))\nprocessed_train_data_dict[warehouse][0].head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model\n- Create time series sequences\n- Create LSTM neural net model\n- Plot loss function history from traing\n- Training loop","metadata":{}},{"cell_type":"code","source":"def create_sequences(X, y=None, time_steps=10):\n    sequences = []\n    targets = []\n\n    if y is not None:\n        # Training mode\n        if len(X) > time_steps:\n            generator = TimeseriesGenerator(X.values, \n                                            y,\n                                            length=time_steps, \n                                            batch_size=1)\n            \n            for i in range(len(generator)):\n                x, y = generator[i]\n                sequences.append(x)\n                targets.append(y)\n        \n        X_seq = np.array(sequences)\n        y_seq = np.array(targets)\n        X_seq = np.squeeze(X_seq, axis=1)\n        y_seq = np.squeeze(y_seq, axis=1)\n        \n        print(f\"Training mode - final shape: X: {X_seq.shape}, y: {y_seq.shape}\")\n        \n        return X_seq, y_seq\n    \n    else:\n        # Inference mode\n        for i in range(len(X) - time_steps + 1):\n            seq = X.iloc[i:(i + time_steps)].values\n            sequences.append(seq)\n        \n        X_seq = np.array(sequences)\n        \n        print(f\"Inference mode - final shape: X: {X_seq.shape}\")\n        \n        return X_seq","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture\nModel from experimenting, simpler gets more constant resulets","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.regularizers import l2\n\n\ndef create_model(input_shape, lr=1e-3, warehouse=\"None\"):\n\n    model = Sequential()\n    model.add(Input(shape=input_shape))\n    \n    if warehouse in [\"Brno_1\", \"Prague_1\", \"Prague_2\", \"Prague_3\"]:\n\n        #model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2()))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.4))\n        \n        #model.add(Bidirectional(LSTM(units=64, activation='relu', return_sequences=True)))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.2))\n        #model.add(LSTM(128, return_sequences=True))\n        model.add(LSTM(1024))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.3))\n        \n        #model.add(Dense(16))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.1))\n    \n        \n    elif warehouse in [\"Munich_1\", \"Frankfurt_1\"]:\n\n        #model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2()))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.3))\n        \n        #model.add(Bidirectional(LSTM(units=64, activation='relu', return_sequences=True)))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.4))\n        model.add(LSTM(512, kernel_regularizer=l2()))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.3))\n        \n        #model.add(Dense(16))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.3))\n    \n    elif warehouse in [\"Budapest_1\"]:\n        #model.add(Conv1D(filters=16, kernel_size=2))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.3))\n        \n        model.add(LSTM(1024, kernel_regularizer=l2()))\n        #model.add(BatchNormalization())\n        #model.add(Dropout(0.3))\n        \n        \n        \n    else:\n        print(\"No model selected, unknown warehouse timeline.\")\n        return\n\n    model.add(Dense(1))\n\n    #model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=lr))\n    model.compile(loss=MeanSquaredError(), optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr, rho=0.9))\n                  \n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(history, warehouse):\n    plt.figure(figsize=(12, 8))\n\n    # training and validation loss\n    plt.plot(history.history['loss'], label='Training Loss', color='blue', linewidth=2)\n    plt.plot(history.history['val_loss'], label='Validation Loss', color='orange', linewidth=2)\n    \n    # minimum validation loss\n    min_val_loss = min(history.history['val_loss'])\n    min_val_loss_epoch = history.history['val_loss'].index(min_val_loss)\n    plt.axvline(min_val_loss_epoch, linestyle='--', color='gray', linewidth=1)\n    plt.text(min_val_loss_epoch, min_val_loss, f'Min Val Loss: {min_val_loss:.4f}', \n             verticalalignment='bottom', horizontalalignment='right', color='gray', fontsize=10)\n    \n    plt.title(f'Training and Validation Loss for Warehouse: {warehouse}', fontsize=16)\n    plt.xlabel('Epoch', fontsize=14)\n    plt.ylabel('Loss', fontsize=14)\n    plt.legend(fontsize=12)\n    plt.grid(True)\n\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.tight_layout()\n    \n    plt.savefig(f'training_validation_loss_{warehouse}.png', dpi=300)\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print nan values for every warehouse in train dataset dict:\nfor warehouse in processed_train_data_dict.keys():\n    print(f\"Nan X values for {warehouse}: {processed_train_data_dict[warehouse][0].isna().sum().sum()}\")\n    print(f\"nan y values for {warehouse}: {sum(np.isnan(processed_train_data_dict[warehouse][1]))}\")\n    \n    if FILL:\n        feat, targ = processed_train_data_dict[warehouse]\n\n        feat = feat.fillna(0)\n        targ = np.nan_to_num(targ, nan=0.0)\n        processed_train_data_dict[warehouse] = (feat, targ)\n\nif FILL:\n    print(\"\\n After FILL:\")\n    for warehouse in processed_train_data_dict.keys():\n        print(f\"Nan X values for {warehouse}: {processed_train_data_dict[warehouse][0].isna().sum().sum()}\")\n        print(f\"nan y values for {warehouse}: {sum(np.isnan(processed_train_data_dict[warehouse][1]))}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Loop\nTraining loop, create sequences, train-test split, create model, use callbacks for trainig, fit the model.","metadata":{}},{"cell_type":"code","source":"#### Training loop:\n\nval_data = {}\ntraining_features = {}\n\nfor warehouse, (X_train_scaled, y_train_scaled) in processed_train_data_dict.items():\n    print(f\"Training model for warehouse: {warehouse}\")\n\n    X_train_scaled = X_train_scaled.drop(columns=['id', 'warehouse', 'date'])\n    \n    training_features[warehouse] = X_train_scaled.columns.tolist()\n\n    # Create sequences\n    X_seq, y_seq = create_sequences(X_train_scaled, y_train_scaled, time_steps=TIME_STEPS)\n    \n    # train-test split\n    X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=True)\n    \n    # Create, compile the model\n    model = create_model(input_shape=(X_train.shape[1], X_train.shape[2]), lr=LEARNING_RATE, warehouse=warehouse)\n    \n    callbacks = [\n        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n        ModelCheckpoint(f'model_{warehouse}.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=1),\n        #ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n    ]\n    \n    # Save the test split of the dataset for each warehouse for future evaluation.\n    val_data[warehouse] = (X_val, y_val)\n    \n    history = model.fit(\n        X_train, y_train, \n        epochs=EPOCHS, \n        batch_size=BATCH_SIZE, \n        #validation_split=0.2, \n        validation_data=(X_val, y_val), \n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    plot_loss(history, warehouse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_scaled.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save all scaler features into a single json scaler config file and save the scaler config so it can be loded for inference.","metadata":{}},{"cell_type":"code","source":"scaler_config = {\n    'bin_features': binary_features,\n    'cat_features': categorical_features,\n    'scaler_features': x_scaler_features,\n    'training_features': training_features,\n}\n\njoblib.dump(scaler_config, 'scaler_config_mt.joblib')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MAPE Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Visualize Predictions on the Training Data","metadata":{}},{"cell_type":"code","source":"#tf.keras.config.enable_unsafe_deserialization()\n\n# Load scalers\n\n# Initialize a list to store MAPE scores\nmape_scores = []\n\n# Loop through each warehouse and calculate MAPE\nfor warehouse, (X_train_scaled, y_train_scaled) in processed_train_data_dict.items():\n    print(f\"Predicting for warehouse: {warehouse}\")\n    y_scaler = joblib.load(f'y_scaler_{warehouse}.joblib')\n    X_train_scaled = X_train_scaled.drop(columns=['id', 'warehouse', 'date'])\n    # Create sequences\n    X_seq, y_seq = create_sequences(X_train_scaled, y_train_scaled, time_steps=TIME_STEPS)\n\n    # Load the model\n    model = tf.keras.models.load_model(f'model_{warehouse}.keras')\n\n    # Predict\n    predictions = model.predict(X_seq)\n    predictions = y_scaler.inverse_transform(predictions)\n    y_seq = y_seq.reshape(-1, 1)\n    y_seq_unscaled = y_scaler.inverse_transform(y_seq)\n\n    # Calculate MAPE\n    mape = mean_absolute_percentage_error(y_seq_unscaled, predictions) * 100\n    mape_scores.append(mape)\n\n    # Visualise the predictions\n    plt.figure(figsize=(15, 5))\n    plt.plot(y_seq_unscaled, label='True', color='black')\n    plt.plot(predictions, label='Predicted', color='red')\n    plt.plot(y_seq_unscaled - predictions, label='Difference', color='blue', linestyle='--')\n    plt.title(f'Predictions vs True for warehouse: {warehouse}')\n    plt.xlabel('Date')\n    plt.ylabel('Orders')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n    print(f'\\nMean Absolute Percentage Error on training data for {warehouse}: {mape:.4f}%')\n\n# Print MAPE scores\nprint(\"\\nMAPE training scores: \")\nfor i, score in enumerate(mape_scores):\n    print(f\"{warehouses[i]}: {score:.4f}%\")\n\nprint(f\"\\nMean training MAPE: {np.mean(mape_scores):.4f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize Predictions on the Validation Data","metadata":{}},{"cell_type":"code","source":"mape_scores = []\n\nfor warehouse in warehouses:\n    print(f\"Predicting for warehouse: {warehouse}\")\n    y_scaler = joblib.load(f'y_scaler_{warehouse}.joblib')\n    # Load the validation data for the current warehouse\n    X_val, y_val = val_data[warehouse]\n    \n    # Load the model\n    model = tf.keras.models.load_model(f'model_{warehouse}.keras')\n        # Predict\n    predictions = model.predict(X_val)\n    predictions = y_scaler.inverse_transform(predictions)\n    y_val = y_val.reshape(-1, 1)\n    y_val_unscaled = y_scaler.inverse_transform(y_val)\n    \n    # Calculate MAPE\n    mape = mean_absolute_percentage_error(y_val_unscaled, predictions) * 100\n    mape_scores.append(mape)\n    \n    # Visualise the predictions\n    plt.figure(figsize=(15, 5))\n    plt.plot(y_val_unscaled, label='True', color='black')\n    plt.plot(predictions, label='Predicted', color='red')\n    plt.plot(y_val_unscaled - predictions, label='Difference', color='blue', linestyle='--')\n    plt.title(f'Predictions vs True for warehouse: {warehouse}')\n    plt.xlabel('Sample')\n    plt.ylabel('Orders')\n    plt.legend()\n    plt.show()\n    \n    print(f'\\nMean Absolute Percentage Error on validation data for {warehouse}: {mape:.4f}%')\n\nprint(\"\\nMAPE validation scores: \")\nfor i, score in enumerate(mape_scores):\n    print(f\"{warehouses[i]}: {score:.4f}%\")\n\nprint(f\"\\nMean validation MAPE: {np.mean(mape_scores):.4f}%\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference and Visualisation on the TEST Data:","metadata":{}},{"cell_type":"markdown","source":"Here we deploy our trained models and run inference on the test data from the challenge. The test data are already preprocessed from the previous step, so we only load them and create LSTM sequences, then predict. If we wanted to take raw test data, we would only need to utilize the \"process_data\" function from the above section first.","metadata":{}},{"cell_type":"markdown","source":"This sequence function is not using the TimeseriesGenerator, because I could not figure out how to use it so it would utilize all the test data rows, there were always leftovers.\nThis function is creating sequences for each row and when it does not have enough data, it is padding the sequence with the first row of the sequence.","metadata":{}},{"cell_type":"markdown","source":"Function that that predicts the test data on multiple timelines - splitting the data for each warehouse, using multiple models.","metadata":{}},{"cell_type":"code","source":"def predict_multiple(data, time_steps, warehouses_trained, training_features):\n    predictions = []\n    submission_data = []\n\n    for warehouse in data['warehouse'].unique():\n        if warehouse not in warehouses_trained:\n            print(f\"No model found for warehouse: {warehouse}\")\n            warehouse_predictions = [np.nan] * len(data[data['warehouse'] == warehouse])\n            predictions.extend(warehouse_predictions)\n            continue\n        model_data = warehouses_trained[warehouse]\n        model = model_data['model']\n        y_scaler = model_data['y_scaler']\n        wh_data = data[data['warehouse'] == warehouse].copy()\n        wh_data = wh_data.reindex(columns=training_features[warehouse])\n    \n\n        sequences = create_sequences(wh_data, None, time_steps)\n        print(f\"{warehouse}: \")\n        print(len(sequences))\n        # Predict on all sequences\n        preds = model.predict(sequences)\n        preds_rescaled = y_scaler.inverse_transform(preds)\n\n        # Align predictions with original data\n        wh_predictions = np.full(len(wh_data), np.nan)\n\n        # Calculate the number of predictions\n        num_predictions = len(preds_rescaled)\n\n        # Assign predictions, accounting for the offset due to sequence creation\n        wh_predictions[-num_predictions:] = preds_rescaled.flatten()\n        predictions.extend(wh_predictions)\n\n        # Prepare submission data\n        wh_submission_data = data.loc[data['warehouse'] == warehouse].copy()\n\n        wh_submission_data['predicted_orders'] = wh_predictions\n\n        submission_data.append(wh_submission_data)\n\n    submission_df = pd.concat(submission_data)\n\n    submission_df.dropna(inplace=True)\n\n    return np.array(predictions), submission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the saved models and scalers for each warehouse. This is optional and a conscious choise to use and is a part of end-to-end approach with potential deployment in mind.","metadata":{}},{"cell_type":"code","source":"def load_models_and_scalers(warehouses):\n    warehouse_models_and_scalers = {}\n\n    for wh in warehouses:\n        try:\n            model = tf.keras.models.load_model(f'model_{wh}.keras')\n            x_scaler = joblib.load(f'x_scaler_{wh}.joblib')\n            y_scaler = joblib.load(f'y_scaler_{wh}.joblib')\n            encoder = joblib.load(f'onehot_scaler_{wh}.joblib')\n            \n            warehouse_models_and_scalers[wh] = {\n                'model': model,\n                'x_scaler': x_scaler,\n                'y_scaler': y_scaler,\n                'encoder': encoder\n            }\n        except Exception as e:\n            print(f\"Error loading model or scaler for warehouse {wh}: {str(e)}\")\n\n    return warehouse_models_and_scalers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we load the scaler configuration and other metadata from the training stage","metadata":{}},{"cell_type":"code","source":"scaler_config = joblib.load('scaler_config_mt.joblib') # load the scaler config\n\nx_scaler_features = scaler_config['scaler_features']   # standard scaler features in the right order that the training dataset was scaled on\ncategorical_features = scaler_config['cat_features']    # categorical features\nbinary_features = scaler_config['bin_features']    # binary features are unpluged before scaling and then plugged back in after scaling\ntraining_features = scaler_config['training_features']    # training features dictionary\n    \nprint(f\"cat_features: {categorical_features}\")\nprint(f\"binary_features: {binary_features}\")\nprint(f\"scaler_columns: {len(x_scaler_features)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Load the saved preprocessed training data","metadata":{}},{"cell_type":"code","source":"dataframe_raw = pd.read_csv(\"/kaggle/working/test_proc_mt.csv\")\ndataframe_raw['date'] = pd.to_datetime(dataframe_raw['date'])\ndataframe = dataframe_raw.sort_values(by=['date', 'warehouse'])\nprint(f\"Rows: {len(dataframe)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load models and predict the test dataset","metadata":{}},{"cell_type":"code","source":"warehouse_lengths = test_df.groupby('warehouse').size()\n\nfor warehouse, length in warehouse_lengths.items():\n    print(f\"{warehouse}: {length}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warehouse_models = load_models_and_scalers(warehouses)\npredictions, submission_df = predict_multiple(dataframe, TIME_STEPS, warehouse_models, training_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = submission_df.rename(columns={\"predicted_orders\": \"orders\"})\n\nsubmission_df = submission_df[submission_df['date'].isin(test_df_raw['date'])]\n\nsubmission_export = submission_df[[\"id\", \"orders\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(processed_test_df))\nprint(len(submission_df))\nprint(sum(submission_df.isna().sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_export.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualise the Test Data Predictions\nVisualise the predictions for 2 months of the test data with the actual data from previous year to see how the predictions fit.","metadata":{}},{"cell_type":"code","source":"# Plot predictions for each warehouse\ntrain_df_raw = pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/train.csv\")\ntrain_df_raw['date'] = pd.to_datetime(train_df_raw['date'])\n\nlast_year_data = train_df_raw[train_df_raw['date'].dt.year > 2022]\n\nfor wh in warehouses:\n\n    wh_df_pred = submission_df[submission_df['warehouse'] == wh]\n    wh_df_pred = wh_df_pred.sort_values(by=['date'])\n    wh_df_last_year = last_year_data[last_year_data['warehouse'] == wh]\n    wh_df_last_year = wh_df_last_year.sort_values(by=['date'])\n    \n    # Plot data (training data from 2023)\n\n    plt.figure(figsize=(12, 6))\n    \n    plt.plot(wh_df_pred.date, wh_df_pred['orders'], label='Predicted',  linestyle='--', color='red')\n\n    plt.plot(wh_df_last_year.date, wh_df_last_year['orders'], label='Actual', color='blue')\n\n    plt.title(f'Predicted vs Actual Orders for {wh} in 2023-2024')\n    plt.xlabel('Date')\n    plt.ylabel('Orders')\n    plt.legend()\n    plt.grid(True)\n    plt.xticks(rotation=45)\n    plt.savefig(f'prediction_plot_{wh}.png')\n    plt.show()\n    plt.close()\n\nprint(\"Predictions complete. Submission file and plots created.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"city = \"Prague_1\"\nsubmission_single_df = submission_df[submission_df['date'].isin(test_df_raw['date'])]\nsubmission_single_df = submission_single_df[submission_single_df.warehouse == city]\nsubmission_single_df = submission_single_df[[\"id\", \"orders\", \"date\", \"warehouse\"]]\nsubmission_single_df.to_csv(f\"/kaggle/working/submission_{city}.csv\", index=False)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_single_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_df_raw = pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/train.csv\")\ntrain_df_raw['date'] = pd.to_datetime(train_df_raw['date'])\n\n#last_year_data = train_df_raw[train_df_raw['date'].dt.year > 2022]\n\n\nwh_df_pred = submission_single_df[submission_single_df['warehouse'] == city]\nwh_df_pred = wh_df_pred.sort_values(by=['date'])\nwh_df_last_year = last_year_data[last_year_data['warehouse'] == city]\nwh_df_last_year = wh_df_last_year.sort_values(by=['date'])\n\n\nplt.figure(figsize=(12, 6))\n\nplt.plot(wh_df_pred.date, wh_df_pred['orders'], label='Predicted',  linestyle='--', color='red')\n\nplt.plot(wh_df_last_year.date, wh_df_last_year['orders'], label='Actual', color='blue')\n\nplt.title(f'Predicted vs Actual Orders for {city}')\nplt.xlabel('Date')\nplt.ylabel('Orders')\nplt.legend()\nplt.grid(True)\nplt.xticks(rotation=45)\nplt.savefig(f'prediction_plot_{wh}.png')\nplt.show()\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing ground:","metadata":{}},{"cell_type":"code","source":"x_val, y_val = val_data[\"Prague_1\"]\nx_val.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val_test = dataframe[dataframe.warehouse == \"Prague_1\"]\nx_val_test_reindex = x_val_test.reindex(columns=training_features[\"Prague_1\"])\nx_test_sequences = create_sequences(x_val_test_reindex, None, TIME_STEPS)\nx_test_sequences.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"array1_flat = x_val.reshape(-1, x_val.shape[-1])\narray2_flat = x_test_sequences.reshape(-1, x_test_sequences.shape[-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1_val = pd.DataFrame(array1_flat)\ndf2_sub = pd.DataFrame(array2_flat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2_sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train_scaled.shape)\nX_train_scaled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf1_val.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(processed_train_data_dict[\"Prague_1\"][0].shape)\nprocessed_train_data_dict[\"Prague_1\"][0].head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(submission_df.shape)\nsubmission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}}]}